services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: admin123
      POSTGRES_DB: postgres
    ports:
      - "5432:5432"
    volumes:
      - ./pgdata:/var/lib/postgresql/data


  airflow-webserver:
    build:
      context: .
      dockerfile: Dockerfile.airflow-secure
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:admin123@postgres/postgres
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      DBT_HOST: postgres
      DBT_USER: postgres
      DBT_PASSWORD: admin123
      DBT_PORT: 5432
      DBT_SCHEMA: mock_schema
    volumes:
      - .:/opt/airflow
      - ./dbt:/opt/airflow/dbt
      - ./transformations:/opt/airflow/transformations
      - ./credentials:/home/airflow/gcloud
      - ./logs:/opt/airflow/logs
      - ./target:/opt/airflow/target
      - ./data:/opt/airflow/data
      - ./dbt/.dbt:/home/airflow/.dbt 
    ports:
      - "8080:8080"
    command: ["airflow", "webserver"]
    restart: always

  airflow-scheduler:
    build:
      context: .
      dockerfile: Dockerfile.airflow-secure
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:admin123@postgres/postgres
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      DBT_HOST: postgres
      DBT_USER: postgres
      DBT_PASSWORD: admin123
      DBT_PORT: 5432
      DBT_SCHEMA: mock_schema
    volumes:
      - .:/opt/airflow
      - ./dbt:/opt/airflow/dbt
      - ./transformations:/opt/airflow/transformations
      - ./credentials:/home/airflow/gcloud
      - ./logs:/opt/airflow/logs
      - ./target:/opt/airflow/target
      - ./data:/opt/airflow/data
      - ./dbt/.dbt:/home/airflow/.dbt 
    command: ["airflow", "scheduler"]
    restart: always

  airflow-init:
    build:
      context: .
      dockerfile: Dockerfile.airflow-secure
    depends_on:
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://postgres:admin123@postgres/postgres
      AIRFLOW__CORE__DAGS_FOLDER: /opt/airflow/dags
      AIRFLOW__LOGGING__BASE_LOG_FOLDER: /opt/airflow/logs
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      DBT_HOST: postgres
      DBT_USER: postgres
      DBT_PASSWORD: admin123
      DBT_PORT: 5432
      DBT_SCHEMA: mock_schema
    volumes:
      - .:/opt/airflow
      - ./dbt:/opt/airflow/dbt
      - ./transformations:/opt/airflow/transformations
      - ./credentials:/home/airflow/gcloud
      - ./logs:/opt/airflow/logs
      - ./target:/opt/airflow/target
      - ./data:/opt/airflow/data
      - ./dbt/.dbt:/home/airflow/.dbt 

    entrypoint: >
      bash -c "
      echo 'Waiting for Postgres...' &&
      while ! pg_isready -h postgres -p 5432; do sleep 1; done &&
      airflow db upgrade &&
      airflow users create --username admin --password admin --firstname Camila --lastname Mu√±oz --role Admin --email admin@example.com"
    restart: "no"

volumes:
  postgres_data: